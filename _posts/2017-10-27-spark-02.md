---
layout: post
title:  "Spark #02 : write to csv file, new line char 문제...해결필요.."
date:   2017-10-30 18:34:01 +0900
tags: [spark, apache spark]
author: ChangHa Choi
---
Spark에서 데이터 처리후 CSV파일로 생성할때 new-line char가 환경에 따라 달라지는 문제가 발생했다.  
OS별로 다른건 괜찮은데, windows의 경우 java project에서 생성된것은 new-line char에 일관성이 없다.   
이렇게 생성된 CSV를 load할때 new-line char에 대한 정의에 따라서 load가 안될수 있어 문제가 되었다.  

python으로는 해보지 않았지만,
application에서의 처리가 아닌 spark 설정상으로 일관성있게 생성할 수 있도록 방법이 있으면 좋겠다.


# Windows
1. spark-shell 에서의 CSV생성
    * 생성하는 코드
```scala
val rdd = sc.parallelize(1 to 100)
rdd.toDF.coalesce(1).write.csv("c:\\test")
```
    * 생성된 결과
```
95[CR][LF]
96[CR][LF]
97[CR][LF]
98[CR][LF]
99[CR][LF]
100[CR][LF]
```
    * ### new-line char가 모두 `CR` `LF`로 적용된다.
        {: style="color:red;"}
1. java project 에서의 CSV생성
    * java code
```java
System.out.println("## start.....");
　
String appName = "work1";
SparkSession spark = sparkContextUtil.getSparkSession(appName);
　
try {
    // read
    Dataset<Row> tmpDS = spark.read()
                        .format("csv")
                        .option("header", "true")
                        .option("inferSchema", "true")
                        .option("delimiter", ",")
                        .option("mode", "DROPMALFORMED")
                        .load("C:\\test\\part-00000-5251acec-1079-4920-8ba0-f4e99e464127-c000.csv");
　
    // write
    File outputPath = new File("C:\\test2");
    tmpDS.toDF().coalesce(1).write()
                            .mode(SaveMode.Overwrite)
                            .option("header", "true")
                            .option("inferSchema", "true")
                            .option("delimiter", ",")
                            .option("quote", "\"")
                            .csv(outputPath.getCanonicalPath());
　
} catch (Exception e) {
    e.printStackTrace();
} finally {
    spark.stop();
}
　
System.out.println("## end.....");
```
    * scala code  
```scala
package com.alklid.spark.test
　      
import org.apache.spark.sql.{SaveMode, SparkSession}
　
object Test {
    def main(args: Array[String]) {
        System.out.println("## start.....")
        val appName = "work1"
        val spark: SparkSession = SparkSession
                                       .builder()
                                       .appName(appName)
                                       .config("spark.master", "local[*]")
                                       .getOrCreate()
　
        try {
            val tmpDS = spark
                       .read
                       .format("csv")
                       .option("header", "true")
                       .option("inferSchema", "true")
                       .option("delimiter", ",")
                       .option("mode", "DROPMALFORMED")
                       .load("C:\\test\\part-00000-c18d0a89-7955-410b-b80d-707cecfa2d00-c000.csv")
 　
            tmpDS
               .toDF
               .write
               .mode(SaveMode.Overwrite)
               .option("header", "true")
               .option("inferSchema", "true")
               .option("delimiter", ",")
               .option("quote", "\"")
               .csv("C:\\test2")
        } catch {
            case e: Exception => e.printStackTrace()
        } finally spark.stop()
　
        System.out.println("## end.....")
    }
}
```
    * 생성된 결과
```
47[CR][LF]
48[CR][LF]
49[CR][LF]
50[LF] --- partition01
51[CR][LF]
...생략...
97[CR][LF]
98[CR][LF]
99[CR][LF]
100[LF] --- partition02
```
    * ### new-line char가 `CR` `LF`로 적용되다가, partition에서 생성되는 파일의 마지막라인에서는 `LF`가 적용된다.
        {: style="color:red;"}

   
   
# Linux - CentOS 7
1. spark-shell 에서의 CSV생성
    * 생성하는 코드
```scala
val rdd = sc.parallelize(1 to 100)
rdd.toDF.coalesce(1).write.csv("/home/sparkTest/test")
```
    * 생성된 결과
```
95[LF]
96[LF]
97[LF]
98[LF]
99[LF]
100[LF]
```
    * ### new-line char가 모두 `LF`로 적용된다.
        {: style="color:red;"}
1. java project 에서의 CSV생성
    * java code : 위의 소스를 동일하게 linux에서 실행했다.
    * 생성된 결과
```
95[LF]
96[LF]
97[LF]
98[LF]
99[LF]
100[LF]
```
    * ### new-line char가 모두 `LF`로 적용된다.
        {: style="color:red;"}

# ! keypoint
spark-shell에서는 new-line char가 동일한데, java application의 경우 OS에 따라 new-line char가 상이하다.