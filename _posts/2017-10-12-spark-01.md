---
layout: post
title:  "Spark #01 : 용어 및 개념정리 첫날..."
date:   2017-10-12 21:47:01 +0900
tags: [spark, apache spark, RDD]
author: ChangHa Choi
---
Apache Spark 학습중... 모르는 용어도 너무 많고, 이해하기 쉽지 않은 개념들도 많고 관련된 stack도 방대함... 

# Big Data Work Flow
1. 데이터 수집
    * Kafka
    * SQOOP
1. 데이터 저장 및 처리
    * Hadoop
        * HDFS(Hadoop distributed file system) : Data 보관
        * MapReduce Framework : Data 처리
        * Yarn : Cluster 자원관리
    * HBase
        * HDFS를 저장소로 사용하는 column 기반 NoSQL DB
    * Cassandra
    * Redis
        * 메모리를 이용한 key/value 저장소
    * Hive
    * Spark
        * 처리결과를 항상 파일시스템에 유지하는 Hadoop과 달리 메모리에 저장하고 관리
        * Hadoop, Hive등과 연동됨
1. 데이터 분석 및 시각화
    * Zeppelin
    * RStudio
   
   
# RDD(Resilient Distributed Dataset)
* 내부에 단위 데이터를 포함
* Read-Only
    * 변형(Transformation)을 하면 기존 RDD가 변형되는것이 아니라, 새로운 변형된 결과의 RDD가 새로 생성된다.
* 저장될때는 여러 서버에 나누어 저장됨
* 처리될때는 각 서버에 저장된 데이터를 동시에 병렬로 처리할 수 있음
    * 처리하는 과정에서 문제가 발생해도 복구 가능
* Partition
    * 하나의 RDD는 여러개의 partition으로 구성되어 있음
    * 작업수행시 partition 단위로 병렬처리됨
        * partition 단위 = 병렬 프로세스의 수
    * 작업이 수행되는 동안 재구성되거나 네트워크를 통해 다른 병렬 서버로 이동(shuffling)될 수 있음, 성능에 영향을 줌.
* Transformation
    * 기존 RDD에 변형(Transformation)을 하면 새로운 RDD가 생성된다.
        * 예) 소문자 데이터를 대문자로 바꿔라
* Action
    * 수행의 결과로 RDD가 아닌, 다른 값을 반환하거나 아예 반환하지 않음
        * 예) 데이터의 총합계를 구해라
        
        
# ! keypoint
* lineage
    * Read-Only RDD가 Transformation/Actions를 통해 새로운 RDD로 만들어지는 과정이 기록된 계보(lineage)
    * Fault-tolerant
        * 데이터 처리 중간에 fault가 생겨도, 해당 데이터(RDD)가 부모 RDD로부터 어떻게 만들어졌는지 기록되어 있음으로 언제든지 다시 만들어 사용할 수 있다.
* Lazy Execution
    * Transformation을 통해서는 RDD의 생성 과정을 lineage에 기록만 해둠
    * Action을 통해서 해당 RDD의 생성 과정을 lineage에서 가져와 순서대로 RDD를 생성하고 Action을 수행함
![RDD Lineage](https://alklid.github.io/dlog/assets/img/2017-10-12-spark-01_apache-storm-vs-spark-streaming-two-stream-processing-platforms-compared-36-638.jpg)


```
# 효율적인 수행이 되도록 lineage를 잘 설계할줄 알아야 하겠다.
```     
    
